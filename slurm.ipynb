{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2825d6cb-e15e-4a79-a3c7-c1a2b5954beb",
   "metadata": {},
   "source": [
    "# Getting started with slurm\n",
    "\n",
    "\n",
    "## Summary \n",
    "\n",
    "In this lab you will learn some of the basics of slurm and a few of the more advanced features that you might helpful in the future. We will be doing this lab on our class cluster but everything we are doing will also work on Stanford's Sherlock system (or any other slurm cluster) often with more interesting results because they are bigger more complex systems.\n",
    "\n",
    "\n",
    "# Slurm basics\n",
    "\n",
    "\n",
    "Slurm is a workload manager. Its jobs is to efficiently and fairly provide cluster resources. A slurm controlled cluster is ususally broken up into parittions where different sets of rules on use and are often composed of different hardware.  You use slurm resources by making a request to the slurm controller node for resources.  Your request is evaluated for priority based on what are referred to as \"fairshare\" rules. When there are free resources and you have the top priority you are granted access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178589bb-4449-4a10-843f-264227c0bc10",
   "metadata": {},
   "source": [
    "## sinfo\n",
    "\n",
    "The sinfo command is very valuable way to find out about a cluster. Using the command without any options will give you a general idea about the cluster you are using.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffc8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb197600",
   "metadata": {},
   "source": [
    "!sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58793c-5747-4e40-80c0-0bda6c0e501a",
   "metadata": {},
   "source": [
    "By default the sinfo command gives you the names of the various partitions, the number of nodes in each partition, their status, and the name of the nodes in the various partitions.  This represents a very small amount of the sinfo commands capabilites. For example I can find the number of cores on a given node using the -n (for a specific node) and -O (for specific information) flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e18390ac-fa4e-4a15-af63-18817cfe6f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORES               \r\n",
      "30                  \r\n"
     ]
    }
   ],
   "source": [
    "!sinfo -n slurm-gp257-devel-compute-3-0 -O CORES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a2f5a-4fa7-49d0-af8d-f8dcb2a04a07",
   "metadata": {},
   "source": [
    "Below are some additional useful options.  Generic resources, Gres, refers to GPUs among other things.\n",
    "\n",
    "\n",
    "| Option | Description|\n",
    "| :--- | ------- |\n",
    "| Cores | Number of cores per socket.|\n",
    "| Disk  | Size of temporary disk space per node in megabytes.|\n",
    "| FreeMem | The total memory, in MB, currently free on the node as reported by the OS. This value is for informational use only and is not used for scheduling.|\n",
    "| Gres  | Generic resources (gres) associated with the nodes. |\n",
    "| GresUsed | Generic resources (gres) currently in use on the nodes. |\n",
    "| Memory | Size of memory per node in megabytes. |\n",
    "| PreemptMode  | Preemption mode. |\n",
    "|  Threads | Number of threads per core. |\n",
    "| Time  |Maximum time for any job in the format \"days-hours:minutes:seconds\". |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec565402-7960-45e7-9957-305f4af2e18e",
   "metadata": {},
   "source": [
    "In the cell below build a table describing the nodes on the cluster using the above commmand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b2c3add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORES               \n",
      "30                  \n",
      "PARTITION           NODES               CORES               TMP_DISK            FREE_MEM            GRES                GRES_USED           MEMORY              PREEMPT_MODE        THREADS             TIMELIMIT           \n",
      "debug*              12                  4                   0                   23462-30758         (null)              gpu:0               31408               OFF                 1                   infinite            \n",
      "cpu                 5                   30                  0                   237889-N/A          (null)              gpu:0               238160              OFF                 1                   infinite            \n",
      "t4                  10                  8                   0                   52016-N/A           gpu:1               gpu:0               59240               OFF                 1                   infinite            \n",
      "preempt             50                  30                  0                   237467-237898       (null)              gpu:0               238160              OFF                 1                   infinite            \n"
     ]
    }
   ],
   "source": [
    "!sinfo -n slurm-gp257-devel-compute-3-0 -O CORES\n",
    "\n",
    "!sinfo -O Partition,Nodes,Cores,Disk,FreeMem,Gres,GresUsed,Memory,PreemptMode,Threads,Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263736a-e55e-4845-b852-b6a6678ef5f6",
   "metadata": {},
   "source": [
    "# squeue\n",
    "\n",
    "Thre squeue command gives us information about what is actually running on the cluster.  Often it useful to use the -p partiton option to reduce the infomation it produces on a cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4706e9-bccb-412a-81ff-c5a08f71ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "              9624     debug     bash jdstitt_  R    2:03:36      1 slurm-gp257-devel-compute-0-0\r\n",
      "             10627     debug     bash ellopes_  R       1:30      1 slurm-gp257-devel-compute-0-1\r\n"
     ]
    }
   ],
   "source": [
    "! squeue -p debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00840058-02c2-4abd-87c8-f232e091b7d8",
   "metadata": {},
   "source": [
    "The results of the command gives you all the jobs that have been submitted to the cluster. It displays the jobid, the parition the job has been submitted, its status, how long it has been running, and the nodes the job is running on.  Below is the list of status possibilites.\n",
    "\n",
    "\n",
    "|Status|Code|Explaination|\n",
    "| ----- | ------ | ----- |\n",
    "|COMPLETED|CD|The job has completed successfully.|\n",
    "|COMPLETING|CG|The job is finishing but some processes are still active.|\n",
    "|FAILED|F|The job terminated with a non-zero exit code and failed to execute.|\n",
    "|PENDING|PD|The job is waiting for resource allocation. It will eventually run.|\n",
    "|PREEMPTED|PR|The job was terminated because of preemption by another job.|\n",
    "|RUNNING|R|The job currently is allocated to a node and is running.|\n",
    "|SUSPENDED|S| A running job has been stopped with its cores released to other jobs.|\n",
    "|STOPPED|ST|A running job has been stopped with its cores retained.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af5cd69-8081-46f0-aada-b7c2ba272059",
   "metadata": {},
   "source": [
    "The squeue and sinfo together provide a powerful tool in combination if you can't figure out why your job isn't starting (or fails)\". Somplex examples include\n",
    "- If you are requesting a job using a number of nodes you can see how many nodes are being currently used. Is it all by one user?\n",
    "- If your job will not start, are you requesting more memory that in on the queue, more processors?\n",
    "- Are other users using up all of the memory /GPUs currently?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a0f1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No, others are not using up all the memory currently for 2/03/2023 @11:12 AM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a1fa7-3ab1-40c3-b3cc-da3ab601e895",
   "metadata": {},
   "source": [
    "# salloc, sbatch, and srun\n",
    "\n",
    "There are two general ways to request slurm resources, salloc and sbatch.  The easiest way to remember the differece is to use salloc when you want to do something interactivelty, sbatch when you are wanting a submit a job that runs eventually.  srun is used to launch jobs on these allocated resources but can be used directly (in whcih case it calls an salloc behind the scenes). \n",
    "\n",
    "The command you used to start this lab is a simple example\n",
    "\n",
    "srun --pty --x11 /bin/bash\n",
    "\n",
    "Here we requesteed a node on the default partition, with the default amount of memory, for the default amount of time, with a single core, said we wanted to run in terminal mode, and ran the command bash. \n",
    "\n",
    "In almost all cases you want to specify the resources you want to use it and the time you want to use them. The primary reason you want to specify the resources you need is the defults are often not approriate. You many need more memory, need more cores, etc. Almost as important is that it can often time give you an advatnage with the scheduler. If your job doesn't take much memory when another user is using most of the memory on a node, your job will start, while someone using the default might not. If the scheduler is trying to run a job that requires many cores, specifying your job will only run for a few minutes, the scheduler will run your job while waiting for other jobs to finish.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14befb10-e4b9-4204-ad74-ed5a3dbff73b",
   "metadata": {},
   "source": [
    "# Specifying job parameters (the basics)\n",
    "\n",
    "We can specify slurm configuration parameters on the command line, or when using sbatch in the submission shell file by begining a line with #SBATCH before specify an option.\n",
    "\n",
    "We can specify the parition using the -partition partName flag. The length of a job with --time=day-hours:minutes:seconds.  We can specify to use gpus by using the gres flag  --gres=gpu[[:type]:number].\n",
    "\n",
    "\n",
    "## Specifying tasks\n",
    "\n",
    "Slurm thinks of a job that has one or tasks. These task(s) run on one or more nodes.  We specify the number of tasks using --ntasks=ntasks.  If each parallel tasks uses multiple cores we can use --cpus-per-task=ncpus.  We can specify multiple tasks per core (--tasks-per-cpu=tasks) or node (--tasks-per-nodes). \n",
    "\n",
    "## Memory\n",
    "\n",
    "There are a number of ways to specify. We can specify the total memory for a job with --mem=<size>units. We can also specify memory per cpu --mem-per-cpu=<size>[units] and per GPU --mem-per-gpu=<size>[units].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21797228",
   "metadata": {},
   "source": [
    "# Simple submission\n",
    "\n",
    "In this part of the lab you will write a simple program to calculate pi using Leibniz’s formula.\n",
    "\n",
    "\n",
    "X = 4 - 4/3 + 4/5 - 4/7 + 4/9 - ....\n",
    "\n",
    "This series is never-ending, the more the terms this series contains, the closer the value of X converges to Pi value.\n",
    "\n",
    "Use the next three cells to \n",
    "\n",
    "- write and save a python script that caclulates Pi using Leibniz formula. You should sum to 1000000 terms.\n",
    "- write a sbatch that\n",
    "    - submits a job to the compute partition\n",
    "    - submits a time limit of 2 hours for the job\n",
    "    - specifies one GB of memory\n",
    "    - runs on a single core\n",
    "- submits the jobs to the cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4077987",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%writefile leib.py #!/usr/bin/env python 3\n",
    "\n",
    "# Do stuff\n",
    "\n",
    "def Leib(N):\n",
    "    summ=0\n",
    "    for i in range(N):\n",
    "        lval=(-1)**i/(2*i+1)\n",
    "        summ=summ+tval\n",
    "    return summ * 4\n",
    "    \n",
    "print(Leib(1000)) #comment on Canvas said to change n to 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84870865",
   "metadata": {},
   "source": [
    "%%writefile submit.sh\n",
    "\n",
    "#SLURM --ntasks=1\n",
    "#SLURM --job-name=SLURMAGE\n",
    "#SLURM --partition=normal\n",
    "#SLURM --time=2:00:00\n",
    "#SLURM --cpus-per-task=1\n",
    "#SLURM --mem-per-cpu=1\n",
    "#SLURM -D /home/ellopes_stanford_edu/slurm\n",
    "#SLURM --output=slurm-%x-%j.out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spack load python\n",
    "python3 ./leib.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df0f4f",
   "metadata": {},
   "source": [
    "!sbatch submit.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5713ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting leib.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile leib.py\n",
    "#!/usr/bin/python\n",
    "\n",
    "def Leib(N):\n",
    "    summ=0\n",
    "    for i in range(N):\n",
    "        lval=(-1)*(-i)/(2*i+1)\n",
    "        summ=summ+lval\n",
    "        \n",
    "    return 4*summ\n",
    "print(Leib(1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12d7e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python\r\n",
      "\r\n",
      "def Leib(N):\r\n",
      "    summ=0\r\n",
      "    for i in range(N):\r\n",
      "        lval=(-1)*(-i)/(2*i+1)\r\n",
      "        summ=summ+lval\r\n",
      "        \r\n",
      "    return 4*summ\r\n",
      "print(Leib(1000000))\r\n"
     ]
    }
   ],
   "source": [
    "!cat leib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a74cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submit.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile submit.sh\n",
    "#!/bin/bash\n",
    "$SLURM --ntasks=1\n",
    "$SLURM --job-name=SLURMAGE\n",
    "$SLURM --partition=normal\n",
    "$SLURM --time=2:00:00\n",
    "$SLURM --cpus-per-task=1\n",
    "$SLURM --mem-per-cpu=1\n",
    "$SLURM -D /home/ellopes_stanford_edu/slurm\n",
    "$SLURM --output=slurm-%x-%j.out\n",
    "$SLURM -e=slurm-%x-%j.err\n",
    "\n",
    "echo \"spack load python@3.10.8\";\n",
    "spack load python@3.10.8;\n",
    "echo \"python --version\";\n",
    "python --version;\n",
    "echo \"python ./leib.py\";\n",
    "python ./leib.py;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4974691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\r\n",
      "$SLURM --ntasks=1\r\n",
      "$SLURM --job-name=SLURMAGE\r\n",
      "$SLURM --partition=normal\r\n",
      "$SLURM --time=2:00:00\r\n",
      "$SLURM --cpus-per-task=1\r\n",
      "$SLURM --mem-per-cpu=1\r\n",
      "$SLURM -D /home/ellopes_stanford_edu/slurm\r\n",
      "$SLURM --output=slurm-%x-%j.out\r\n",
      "$SLURM -e=slurm-%x-%j.err\r\n",
      "\r\n",
      "echo \"spack load python@3.10.8\";\r\n",
      "spack load python@3.10.8;\r\n",
      "echo \"python --version\";\r\n",
      "python --version;\r\n",
      "echo \"python ./leib.py\";\r\n",
      "python ./leib.py;\r\n"
     ]
    }
   ],
   "source": [
    "!cat submit.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c616202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 10628\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch submit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f3ab1",
   "metadata": {},
   "source": [
    "# Slurm advanced\n",
    "\n",
    "Slurm also has a number of advanced options that can be quite useful.  \n",
    "\n",
    "## Resubmitting\n",
    "\n",
    "Clusters are always trying to maximize there usage.  As a result they often have a mechanism that allows unused resources used for free at or a reduced cost. In general you get to use these resources until someone who has/or is willing to pay/has paid a higher cost. At Stanford, the Sherlock clusters owner's queue operates in this manner. If you submit a job to the queue it will use all free resources if the owner of the resource requests those resources your job will be killed. GCP has the concept of preemitbible nodes, which opperate at a much lower cost, but the jobs can be killed at any time.\n",
    "\n",
    "Many applications can take advantage of these potentially killed resources.  They are ideal for jobs that take a short time and don't use many cores. Slurm provides the option --requeue to enable the use of these resources.  Any job that doesn't complete is automatically resubmitted to the queue.\n",
    "\n",
    "## Job arrays\n",
    "\n",
    "There are many cases where you want to run a series of very similar jobs. Each job could be submitted in sequence but this can overload a slurm controller load.  Slurm job arrays provide an effective way to approach these jobs. The command line option --array offers a potential solution. You can submit an array in many forms:\n",
    "\n",
    "- --array=0-31    # jobs 0 1 2 3 4 5 .. 31\n",
    "- --array=1,3,5,7 # jobs 1 3 5 7\n",
    "-  --array=1-7:2  # jobs 1 3 4 5 7\n",
    "\n",
    "Each job will set the environmental variable SLURM_ARRAY_TASK_ID with the corresponding ID.\n",
    "\n",
    "\n",
    "## Dependency\n",
    "\n",
    "Another powerful feature of slurm is the ability to build dependencies. Basically guarantee that a task doesn't start until a given condition has been met. You can set a dependency using --dependency=<type:job_id[:job_id] where type is one of the following.\n",
    "\n",
    "\n",
    "- after:jobid[:jobid...]\tjob can begin after the specified jobs have started\n",
    "- afterany:jobid[:jobid...]\tjob can begin after the specified jobs have terminated\n",
    "- afternotok:jobid[:jobid...]\tjob can begin after the specified jobs have failed\n",
    "- afterok:jobid[:jobid...]\tjob can begin after the specified jobs have run to completion with an exit code of zero (see the user guide for caveats).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467bc972",
   "metadata": {},
   "source": [
    "# Complex submission\n",
    "\n",
    "A second way to calculate pi is to use random numbers. You can calculate pi by taking by \n",
    " - choosing two random numbers between 0 and 1\n",
    " - checking whether to sum of the squares of those numbers is <= 1\n",
    " - 4 times the fraction of numbers that meet this criteria will be equal to pi\n",
    "\n",
    "\n",
    "Your job is to\n",
    "\n",
    "- write a program that follows the above procedure to estimate pi using a large number of tests\n",
    "    - it should seed to random number generated based on reading the environmental variable SLURM_ARRAY_TASK_ID.\n",
    "    - it should write the estimate to a file that uses the SLURM_ARRAY_TASK_ID in its name\n",
    "- You should write a second program that reads a series of files with the name pattern above and averaes them and writes the result to result2.txt.\n",
    "- You should write two slurm submission scripts\n",
    "    - The First should submit to the preempt partition a job array of 1000 and resubmit if the job fails (make sure you test your code by running it on this node before submitting)\n",
    "    - The second job should depend on the first job finishing with an exit code 0 befofre running the second python script. This job should run on debug partition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034b739",
   "metadata": {},
   "source": [
    "# Finishing up\n",
    "\n",
    "Add this lab to your class github site after adding all of the files that you have created for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123652ee",
   "metadata": {},
   "source": [
    "Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4325369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting piapprox.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile piapprox.py\n",
    "#!/bin/bash\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "Numtests=10000\n",
    "\n",
    "outputdir=os.getcwd()\n",
    "#'/home/ellopes_stanford_edu/slurm/pioutput'\n",
    "#env='SLURM_ARRAY_TASK_ID'\n",
    "#print(outputdir[60:])\n",
    "#ID=int(outputdir[60:])\n",
    "\n",
    "slurmjob=int(sys.argv[1])\n",
    "\n",
    "seedy1=random.seed(slurmjob)\n",
    "seedy2=random.seed(slurmjob+1) #did this such that there are two different random numbers \n",
    "\n",
    "#--array=0-Numtests\n",
    "i=0\n",
    "yes=0\n",
    "no=0\n",
    "#random.seed(sa_t_id)\n",
    "while i<Numtests:\n",
    "    #rand1=random.random()\n",
    "    rand1=seedy1\n",
    "    rand2=seedy2\n",
    "    #rand2=random.random()\n",
    "    #randarray=[rand1,rand2]\n",
    "    if rand1**2+rand2**2<=1:\n",
    "        #randratio=min(randarray)/max(randarray)\n",
    "        yes+=1\n",
    "    else:\n",
    "        no+=1\n",
    "    i+=1\n",
    "approx=4*yes/(yes+no)\n",
    "approxarray=[approx]\n",
    "print(approx)\n",
    "#purpose is can you make a job wait on a job\n",
    "#make a temp directory\n",
    "#np.savetext('results1'+ (SLURM_ARRAY_TASK_ID) +'.txt', delimiter=\",\")\n",
    "#with open('results1.txt', 'w') as a:\n",
    "#    a.write(approx)\n",
    "np.savetxt('results1_task'+str(sys.argv[1])+'.csv',approxarray)\n",
    "#with open('results1.csv', 'w') as a:\n",
    "#    a.write(str(approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c79da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting results1.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile results1.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --array=1-1000\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --job-name=COMPLICATED\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH -D /home/ellopes_stanford_edu/slurm\n",
    "#SBATCH --output=slurm-%x-%j.out\n",
    "#SBATCH -e slurm-%x-%j.err\n",
    "\n",
    "\n",
    "echo \"export PATH=${PATH}:/home/spack/spack/bin\";\n",
    "export PATH=\"${PATH}:/home/spack/spack/bin\";\n",
    "echo \". /home/spack/spack/share/spack/setup-env.sh\";\n",
    ". /home/spack/spack/share/spack/setup-env.sh;\n",
    "\n",
    "echo \"spack load python@3.10.8\";\n",
    "spack load python@3.10.8;\n",
    "echo \"python --version\";\n",
    "python --version;\n",
    "echo \"python ./piapprox.py\";\n",
    "python ./piapprox.py $SLURM_ARRAY_TASK_ID;\n",
    "exit 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a733ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting puttogether.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile puttogether.py\n",
    "#!/bin/bash\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "piguesses=glob.glob('**.csv', recursive=True)\n",
    "#print(piguesses)\n",
    "li = []\n",
    "for f in piguesses:\n",
    "    with open(f) as file:\n",
    "        contents = file.read()\n",
    "        contents = float(contents)\n",
    "        li.append(contents)\n",
    "    # read in csv\n",
    "    #temp_df = pd.read_csv(f)\n",
    "    #append df to list\n",
    "    #li.append(temp_df)\n",
    "\n",
    "#for filename in os.listdir(os.getcwd()):\n",
    "#   with open(os.path.join(os.getcwd(), filename), 'r') as f: # open in readonly mode\n",
    "#        piguesses.append(piapprox)\n",
    "\n",
    "finalpi=np.mean(li)\n",
    "finalguess=[finalpi]\n",
    "np.savetxt('results2.txt',finalguess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9a3fee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting results2.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile results2.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --array=1\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --exclusive\n",
    "#SBATCH --job-name=COMPLICATED\n",
    "#SBATCH --partition=debug\n",
    "#SBATCH --time=2:00:00\n",
    "#SBATCH -D /home/ellopes_stanford_edu/slurm\n",
    "#SBATCH --output=slurm-%x-%j.out\n",
    "#SBATCH -e slurm-%x-%j.err\n",
    "\n",
    "echo \"export PATH=${PATH}:/home/spack/spack/bin\";\n",
    "export PATH=\"${PATH}:/home/spack/spack/bin\";\n",
    "echo \". /home/spack/spack/share/spack/setup-env.sh\";\n",
    ". /home/spack/spack/share/spack/setup-env.sh;\n",
    "\n",
    "echo \"spack load python@3.10.8\";\n",
    "spack load python@3.10.8;\n",
    "echo \"python --version\";\n",
    "python --version;\n",
    "echo \"python ./pulltogether.py\";\n",
    "python ./pulltogether.py $SLURM_ARRAY_TASK_ID;\n",
    "exit 0;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "358d9bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsub_out=!sbatch results1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3a945428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Submitted batch job 11257']\n"
     ]
    }
   ],
   "source": [
    "print(jsub_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "31c3f9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n",
      "           11215_1     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_2     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_3     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_4     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_5     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_6     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_7     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_8     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "           11215_9     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_10     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_11     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_12     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_13     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_14     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_15     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_16     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_17     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_18     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_19     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_20     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_21     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_22     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_23     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_24     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_25     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_26     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_27     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_28     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_29     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_30     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_31     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_32     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_33     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_34     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_35     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_36     debug COMPLICA ellopes_ CG       0:09      1 \n",
      "          11215_37     debug COMPLICA ellopes_ CG       0:10      1 \n",
      "          11215_38     debug COMPLICA ellopes_ CG       0:10      1 \n",
      "          11215_39     debug COMPLICA ellopes_ CG       0:10      1 \n",
      "          11215_40     debug COMPLICA ellopes_ CG       0:10      1 \n",
      "   11215_[41-1000]     debug COMPLICA ellopes_ PD       0:00      1 (Resources)\n",
      "       11256_[1-2]     debug COMPLICA ellopes_ PD       0:00      1 (Dependency)\n",
      "       11257_[1-2]     debug COMPLICA ellopes_ PD       0:00      1 (None)\n",
      "             10627     debug     bash ellopes_  R    1:40:13      1 slurm-gp257-devel-compute-0-1\n"
     ]
    }
   ],
   "source": [
    "!squeue -u \"$USER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc89b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "08f37388",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_jid = jsub_out[0].split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1f74e9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afterok:11257\r\n"
     ]
    }
   ],
   "source": [
    "!echo {'afterok:'+str(prev_jid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a46663b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 11258\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch --dependency={'afterok:' + str(prev_jid)} results2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4960d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_list = []\n",
    "#for root, dirs, files in os.walk(<path to your folder>):\n",
    "#    for file in files:\n",
    "#        if file.endswith('.txt')\n",
    "#            with open(os.path.join(root, file), 'r') as f:\n",
    "#                text = f.read()\n",
    "#                new_list.append(text)\n",
    "#print(np.mean(new_list))\n",
    "#np.savetext('results2'+'.txt', np.mean(new_list,delimiter=\",\")\n",
    "#look up glob -- *.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slurm submission?\n",
    "#afternotok:jobid[:jobid...]\n",
    "#afterok:jobid[:jobid...] j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
